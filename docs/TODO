[] Add n-kv-heads
[] support 16fp and run 7B llama
[] update format with checksum, so we can load our own models
